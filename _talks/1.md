---
Index: 1
style: "border-radius: 20px; background-color: #F0F0F0;padding-top:16px;padding-bottom:16px;padding-left:32px;padding-right:32px;"
Name: "Huan Wang"
Affilication: PhD Candidate, Northeastern University
Profile: https://huanwang.tech/
photo: https://huanwang.tech/images/profile_v2.jpg
Date: 9th February
Location: BYENG-361, ASU
Time: 14:00 - 15:00 MST
YTLink: #
aff_photo: https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Northeastern_seal.svg/800px-Northeastern_seal.svg.png
Title: Efficient Mobile Text-to-Image Diffusion Models
Details: Diffusion models (DMs) trained on enormous text-image pairs, such as Stable Diffusion, DALL-E, have revolutionized the field visual information generation with their exceptional quality. However, the superior quality of these models is offset by their substantial size and the consequent slow inference speed, a challenge that becomes even more pronounced on mobile devices. In this talk, I will first discuss the challenges of running text-to-image DMs on mobile devices. Then, I shall introduce our NeurIPS’23 work, “SnapFusion -- Text-to-Image Diffusion Model on Mobile Devices within Two Seconds”, which is known as the first approach that can achieve text-to-image generation in less than 2 seconds on a mobile device. Particularly, I shall explain how we significantly improve the inference efficiency through a joint optimization of the network architecture and training strategy. Other relevant works (e.g., Google's recent work, MobileDiffusion) will also be discussed. Finally, a summary and outlook of the mobile DMs in the future will conclude the talk.
Bio: 
---
