---
Index: 0
style: "border-radius: 20px; background-color: #F0F0F0;padding-top:16px;padding-bottom:16px;padding-left:32px;padding-right:32px;"
Name: "Yilun Du"
Affilication: PhD Candidate, MIT
Profile: https://yilundu.github.io/
photo: https://yilundu.github.io/images/yilun3.png
Date: 26th January
Location: BYENG-361, ASU
Time: 13:00 - 14:00 MST
ZoomLink: https://asu.zoom.us/meeting/register/tZ0scu2gqzkqH9AlBRhw4TBQBlU2a4ZsC_ZV
aff_photo: https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/MIT_logo.svg/2560px-MIT_logo.svg.png
Title: Generalizing Outside the Training Distribution through Compositional Generation
Details: Generative AI has led to stunning successes in recent years but is fundamentally limited by the amount of data available.  This is especially limiting in the embodied setting – where an agent must make decisions in completely new environments. In this talk, I’ll introduce the idea of compositional generative modeling, which can significantly reduce needed data requirements by building complex generative models from smaller constituents. I’ll first introduce the idea of energy-based models and illustrate how they enable compositional generative modeling. I’ll then illustrate how such compositional models enable the synthesis of complex plans in novel environments as well as complex visual scenes in unseen environments. Finally, I'll show how such compositionality can be applied to multimodal models to construct decision making systems that can hierarchically plan to solve long-horizon problems.
Bio: Yilun Du is final year PhD student at MIT. He is supported by the NSF Graduate Research Fellowship and was previously a research fellow at OpenAI, a visiting researcher at FAIR and a student researcher at Google Deepmind.
---
